{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAJRnwSBQNbQ"
      },
      "source": [
        "# Timbre classifier\n",
        "Continuation of my master thesis work of the title:  \n",
        "\"*Embedded Real-time Classification Of Percussive And Pitched Sounds On A Smart Guitar*\"\n",
        "\n",
        "This notebook loads a dataset of feature vectors extracted from **pitched** and **percussive** sounds recorded with many acoustic guitars.\n",
        "The techniques/classes recorded are:  \n",
        "0.    **Kick**      (Palm on lower body)\n",
        "1.    **Snare 1**   (All fingers on lower side)\n",
        "2.    **Tom**       (Thumb on higher body)\n",
        "3.    **Snare 2**   (Fingers on the muted strings, over the end\n",
        "of the fingerboard)\n",
        "___\n",
        "4.    **Natural Harmonics** (Stop strings from playing the dominant frequency, letting harmonics ring)\n",
        "5.    **Palm Mute** (Muting partially the strings with the palm\n",
        "of the pick hand)\n",
        "6.    **Pick Near Bridge** (Playing toward the bridge/saddle)\n",
        "7.    **Pick Over the Soundhole** (Playing over the sound hole)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a2ha_JDqV9I"
      },
      "source": [
        "## Import modules and mount drive folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw8otQ7AQMaV",
        "outputId": "975de682-b8a5-491f-d0e1-d82e3803b6a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.4.1\n",
            "Not running on CoLab\n"
          ]
        }
      ],
      "source": [
        "REQUIRE_GPU = False\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard \n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version: \" + tf.version.VERSION)\n",
        "import time\n",
        "from tensorflow import keras\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics\n",
        "\n",
        "global_random_state = 42\n",
        "np.random.seed(global_random_state)\n",
        "tf.random.set_seed(global_random_state)\n",
        "\n",
        "COLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if COLAB:\n",
        "    print('Running on CoLab')\n",
        "    #Connect and mount the drive folder that contains the train dataset and the output folder\n",
        "    from google.colab import drive\n",
        "    HOMEBASE = \"/content/gdrive/MyDrive/dottorato/Publications/02-IEEE-RTEmbeddedTimbreClassification(submitted)/MLClassifiers\"\n",
        "    DATAFOLDER = HOMEBASE + \"/data\"\n",
        "    MODELFOLDER = HOMEBASE + \"/output\"\n",
        "    drive.mount('/content/gdrive', force_remount=False)\n",
        "    THISDIR = \"/content/\"\n",
        "else:\n",
        "    print('Not running on CoLab')\n",
        "    HOMEBASE = \".\"\n",
        "    DATAFOLDER = HOMEBASE + \"/data\"\n",
        "    MODELFOLDER = HOMEBASE + \"/output\"\n",
        "    THISDIR = \"./\"\n",
        "\n",
        "RELIEF_CACHE_FILEPATH = DATAFOLDER + '/relief_cache.pickle'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BxHBUDQPXKS",
        "outputId": "628d8428-14d1-4ec8-dc6b-c4a29058d8aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-21 17:25:39.162020: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-09-21 17:25:39.167377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2022-09-21 17:25:40.767337: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-21 17:25:40.767674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 Ti computeCapability: 7.5\n",
            "coreClock: 1.485GHz coreCount: 16 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 178.84GiB/s\n",
            "2022-09-21 17:25:40.767708: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-09-21 17:25:40.829460: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
            "2022-09-21 17:25:40.829562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
            "2022-09-21 17:25:40.849687: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-09-21 17:25:40.852888: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-09-21 17:25:40.928987: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-09-21 17:25:40.932232: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-09-21 17:25:40.986772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-09-21 17:25:40.987019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-21 17:25:40.987464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-21 17:25:40.987746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2022-09-21 17:25:40.988053: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
            "\n",
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-21 17:25:41.795803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-09-21 17:25:41.795829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2022-09-21 17:25:41.795835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2022-09-21 17:25:41.796277: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-21 17:25:41.796655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-21 17:25:41.796968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-21 17:25:41.797242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3409 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
            "2022-09-21 17:25:41.798361: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-09-21 17:25:41.799542: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2022-09-21 17:25:41.799636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-21 17:25:41.799907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 Ti computeCapability: 7.5\n",
            "coreClock: 1.485GHz coreCount: 16 deviceMemorySize: 3.82GiB deviceMemoryBandwidth: 178.84GiB/s\n",
            "2022-09-21 17:25:41.799932: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-09-21 17:25:41.799955: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
            "2022-09-21 17:25:41.799974: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
            "2022-09-21 17:25:41.800000: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2022-09-21 17:25:41.800027: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2022-09-21 17:25:41.800054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-09-21 17:25:41.800082: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-09-21 17:25:41.800108: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-09-21 17:25:41.800187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-21 17:25:41.800630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-09-21 17:25:41.800892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
          ]
        }
      ],
      "source": [
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
        "print(tf.config.list_physical_devices(\"GPU\"))\n",
        "\n",
        "if REQUIRE_GPU:\n",
        "  assert len(tf.config.experimental.list_physical_devices('GPU')) >= 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8ZMbpx2eM2G"
      },
      "source": [
        "## Check Real avaliable GRAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "R_8hnGH7eL_T"
      },
      "outputs": [],
      "source": [
        "CHECK_GRAM = False\n",
        "\n",
        "if CHECK_GRAM:\n",
        "    # memory footprint support libraries/code\n",
        "    !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "    !pip install gputil\n",
        "    !pip install psutil\n",
        "    !pip install humanize\n",
        "    import psutil\n",
        "    import humanize\n",
        "    import os\n",
        "    import GPUtil as GPU\n",
        "    GPUs = GPU.getGPUs()\n",
        "    # XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "    gpu = GPUs[0]\n",
        "    def printm():\n",
        "        process = psutil.Process(os.getpid())\n",
        "        print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "        print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "    printm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2hdmJnSsEOM"
      },
      "source": [
        "# Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FSKxb5DSsU5",
        "outputId": "6b34af90-cbfb-42dd-8b1b-7385c481022f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading dataset...\n",
            "Dataset read\n",
            "Dataset entries: 17604\n",
            "Dataset features: 495\n"
          ]
        }
      ],
      "source": [
        "print(\"Reading dataset...\")\n",
        "original_dataset_features = pd.read_csv(DATAFOLDER + \"/dataset_x.csv\",sep=',',decimal = '.')\n",
        "original_dataset_features = original_dataset_features.loc[:, ~original_dataset_features.columns.str.contains('^Unnamed')] # to fix error in loading\n",
        "dataset_labels = pd.read_csv(DATAFOLDER + \"/dataset_y.csv\",sep=',',decimal = '.')\n",
        "\n",
        "CLASSES_DESC = {0:\"Kick\",\n",
        "                1:\"Snare 1\",\n",
        "                2:\"Tom\",\n",
        "                3:\"Snare 2\",\n",
        "                4:\"Natural Harmonics\",\n",
        "                5:\"Palm Mute\",\n",
        "                6:\"Pick Near Bridge\",\n",
        "                7:\"Pick Over the Soundhole\"}\n",
        "CLASSES = list(CLASSES_DESC.keys())\n",
        "\n",
        "assert np.equal(np.sort(CLASSES),np.sort(pd.unique(dataset_labels['Timbre Label']))).all()\n",
        "\n",
        "# Drop problematic features\n",
        "original_dataset_features = original_dataset_features.drop(columns=['attackTime_peaksamp'])\n",
        "original_dataset_features = original_dataset_features.drop(columns=['attackTime_attackStartIdx'])\n",
        "original_dataset_features = original_dataset_features.drop(columns=['peakSample_index'])\n",
        "\n",
        "\n",
        "print(\"Dataset read\")\n",
        "print(\"Dataset entries: \"+str(original_dataset_features.shape[0]))\n",
        "print(\"Dataset features: \"+str(original_dataset_features.shape[1]))\n",
        "\n",
        "original_feature_number = original_dataset_features.shape[1]\n",
        "(relief_data_X,relief_data_y) = (original_dataset_features.values,dataset_labels.values.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2gv9fFFavMz",
        "outputId": "bfa24868-4bb7-4edb-d93c-dd71125d512f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a98c6e0a3e457a73ebce080b7d0bcb5378b7c7f58701989d1a58e5b66166d1f5\n",
            "f4b930c95faf157dc7140e296d37323df41fcd6c4547e7fbe719c547515b5adc\n"
          ]
        }
      ],
      "source": [
        "# Compute has of the dataset files.\n",
        "# This are used to cache precomputed feature selection with ReliefF (Which is rather slow)\n",
        "import hashlib\n",
        " \n",
        "dataset_X_sha256_hash = hashlib.sha256()\n",
        "dataset_y_sha256_hash = hashlib.sha256()\n",
        "with open(DATAFOLDER + \"/dataset_x.csv\",\"rb\") as fX, open(DATAFOLDER + \"/dataset_y.csv\",\"rb\") as fy:\n",
        "    for byte_block in iter(lambda: fX.read(4096),b\"\"):    # Read and update hash string value in blocks of 4K\n",
        "        dataset_X_sha256_hash.update(byte_block)\n",
        "    for byte_block in iter(lambda: fy.read(4096),b\"\"):    # Read and update hash string value in blocks of 4K\n",
        "        dataset_y_sha256_hash.update(byte_block)\n",
        "dataset_X_sha256_hash = dataset_X_sha256_hash.hexdigest()\n",
        "dataset_y_sha256_hash = dataset_y_sha256_hash.hexdigest()\n",
        "\n",
        "print(dataset_X_sha256_hash)\n",
        "print(dataset_y_sha256_hash)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjF3Cif5zr1p"
      },
      "source": [
        "## Subset features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "54W94nlS5U-y"
      },
      "outputs": [],
      "source": [
        "from IPython.core.magic import register_cell_magic\n",
        "\n",
        "@register_cell_magic\n",
        "def write_and_run(line, cell):\n",
        "    argz = line.split()\n",
        "    file = argz[-1]\n",
        "    mode = 'w'\n",
        "    if len(argz) == 2 and argz[0] == '-a':\n",
        "        mode = 'a'\n",
        "    with open(file, mode) as f:\n",
        "        f.write(cell)\n",
        "    get_ipython().run_cell(cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "--hCfGHKZK98"
      },
      "outputs": [],
      "source": [
        "def get_manual_selected_features(data):\n",
        "    print (\"Subsetting features...\")\n",
        "    columns_to_keep = []\n",
        "    # if USE_ATTACKTIME_PEAKSAMP:\n",
        "    #     columns_to_keep.append(\"attackTime_peaksamp\")\n",
        "    # if USE_ATTACKTIME_ATTACKSTARTIDX:\n",
        "    #     columns_to_keep.append(\"attackTime_attackStartIdx\")\n",
        "    if USE_ATTACKTIME_VALUE:\n",
        "        columns_to_keep.append(\"attackTime_value\")\n",
        "    if USE_BARKSPECBRIGHTNESS:\n",
        "        columns_to_keep.append(\"barkSpecBrightness\")\n",
        "    if USE_PEAKSAMPLE_VALUE:\n",
        "        columns_to_keep.append(\"peakSample_value\")\n",
        "    # if USE_PEAKSAMPLE_INDEX:\n",
        "    #     columns_to_keep.append(\"peakSample_index\")\n",
        "    if USE_ZEROCROSSING:\n",
        "        columns_to_keep.append(\"zeroCrossing\")\n",
        "\n",
        "    assert USE_BARKSPEC <= 50 and USE_BARKSPEC >= 0 and USE_BFCC <= 49 and USE_BFCC >= 0 and USE_CEPSTRUM <= 353 and USE_CEPSTRUM >= 0 and USE_MFCC <= 37 and USE_MFCC >= 0\n",
        "\n",
        "    if USE_BARKSPEC > 0:\n",
        "        columns_to_keep += ['barkSpec_'+str(i+1) for i in range(USE_BARKSPEC)]\n",
        "    if USE_BFCC > 0:\n",
        "        columns_to_keep += ['bfcc_'+str(i+2) for i in range(USE_BFCC)]  # +2 is correct here since we want to skip the first normalized coefficient\n",
        "    if USE_CEPSTRUM > 0:\n",
        "        columns_to_keep += ['cepstrum_'+str(i+1) for i in range(USE_CEPSTRUM)]\n",
        "    if USE_MFCC > 0:\n",
        "        columns_to_keep += ['mfcc_'+str(i+2) for i in range(USE_MFCC)]  # +2 is correct here since we want to skip the first normalized coefficient\n",
        "\n",
        "    return columns_to_keep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "agcUWSWVbokS"
      },
      "outputs": [],
      "source": [
        "## To Compeltely reset RelieFF cache\n",
        "# with open(RELIEF_CACHE_FILEPATH, 'wb') as rcf:\n",
        "#     pickle.dump(set(), rcf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PBDXJV0dnx2W"
      },
      "outputs": [],
      "source": [
        "\n",
        "        \n",
        "# how_many_examples_per_class =10\n",
        "# subselection = list(range(0,how_many_examples_per_class))+\\\n",
        "#                list(range(600,600+how_many_examples_per_class))+\\\n",
        "#                list(range(1100,1100+how_many_examples_per_class))+\\\n",
        "#                list(range(1400,1400+how_many_examples_per_class))+\\\n",
        "#                list(range(1900,1900+how_many_examples_per_class))+\\\n",
        "#                list(range(3000,3000+how_many_examples_per_class))+\\\n",
        "#                list(range(9000,9000+how_many_examples_per_class))+\\\n",
        "#                list(range(14000,14000+how_many_examples_per_class))\n",
        "\n",
        "# testprova_dataset_features = original_dataset_features.iloc[subselection]\n",
        "# testprova_dataset_labels = dataset_labels.iloc[subselection]\n",
        "import os, platform, subprocess, re\n",
        "\n",
        "def get_processor_name():\n",
        "    if platform.system() == \"Windows\":\n",
        "        return platform.processor()\n",
        "    elif platform.system() == \"Darwin\":\n",
        "        os.environ['PATH'] = os.environ['PATH'] + os.pathsep + '/usr/sbin'\n",
        "        command =\"sysctl -n machdep.cpu.brand_string\"\n",
        "        return subprocess.check_output(command).strip()\n",
        "    elif platform.system() == \"Linux\":\n",
        "        command = \"cat /proc/cpuinfo\"\n",
        "        all_info = subprocess.check_output(command, shell=True).decode().strip()\n",
        "        for line in all_info.split(\"\\n\"):\n",
        "            if \"model name\" in line:\n",
        "                return re.sub( \".*model name.*:\", \"\", line,1)\n",
        "    return \"\"\n",
        "\n",
        "class ReliefCacheElem(dict):\n",
        "\n",
        "    PRINT_HASH = False\n",
        "\n",
        "    def __init__(self,dataset_X_sha256,dataset_y_sha256,n_neighbors,relieff_top_features,relieff_feature_importances,time_of_computation):\n",
        "        self.dataset_X_sha256 = dataset_X_sha256\n",
        "        self.dataset_y_sha256 = dataset_y_sha256\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.relieff_top_features = relieff_top_features\n",
        "        self.relieff_feature_importances = relieff_feature_importances\n",
        "        self.date = time.strftime(\"%Y/%m/%d-%H:%M:%S\")\n",
        "\n",
        "        self.cpu_info = get_processor_name()\n",
        "        self.time_of_computation = time_of_computation\n",
        "\n",
        "    def __key(self):\n",
        "        return tuple([self.dataset_X_sha256,\n",
        "                     self.dataset_y_sha256,\n",
        "                     self.n_neighbors,\n",
        "                     str(self.relieff_top_features),\n",
        "                     str(self.relieff_feature_importances)])\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.__key())\n",
        "\n",
        "    def __str__(self):\n",
        "        res = '{date: '+self.date+', n_neighbors:'+str(self.n_neighbors)\n",
        "        \n",
        "        if self.PRINT_HASH:\n",
        "            res += 'dataset_X_sha256:'+str(self.dataset_X_sha256)+','+'dataset_y_sha256:'+str(self.dataset_y_sha256)+','\n",
        "\n",
        "        res += 'cpu_info:'+str(self.cpu_info)+','\n",
        "        res += 'time_of_computation:'+str(self.time_of_computation)+','\n",
        "        res += '}'\n",
        "        return res\n",
        "\n",
        "\n",
        "def relieff_selection(X:list,y:list,n_features,n_neighbors,relief_cache_filepath,verbose_ = True):\n",
        "    relief_data_X = X\n",
        "    relief_data_y = y\n",
        "    relief_top_features_ = None\n",
        "    relief_feature_importances_ = None\n",
        "    # First check if result is already cached\n",
        "    ## Load Cache\n",
        "    relief_cache = None\n",
        "\n",
        "    ##----------------------------------------------##\n",
        "    if not os.path.exists(relief_cache_filepath):\n",
        "        raise Exception(\"RELIEF CACHE NOT FOUND at '\"+relief_cache_filepath+\"'! Comment exception to create empty cache\")\n",
        "        with open(relief_cache_filepath, 'wb') as rcf:\n",
        "            pickle.dump(set(), rcf)\n",
        "    ##----------------------------------------------##\n",
        "\n",
        "    with open(relief_cache_filepath,'rb') as rcf:\n",
        "        relief_cache = pickle.load(rcf)\n",
        "        if verbose_: \n",
        "            print('Loaded Relief cache ('+str(len(relief_cache))+' solutions)')\n",
        "    # Check if present\n",
        "    for cache_elem in relief_cache:\n",
        "        if cache_elem.dataset_X_sha256 == dataset_X_sha256_hash and\\\n",
        "           cache_elem.n_neighbors == n_neighbors:\n",
        "            if verbose_:\n",
        "                print(\"Result found in cache!\")\n",
        "            return cache_elem.relieff_top_features[:n_features]\n",
        "    \n",
        "    # If not present, compute\n",
        "    if verbose_:\n",
        "        print(\"Result NOT found in cache, computing now... (might take a long while)\")\n",
        "    \n",
        "    from skrebate import ReliefF\n",
        "    r = ReliefF(n_neighbors=n_neighbors,verbose=verbose_)\n",
        "    \n",
        "    start_fit = time.time()\n",
        "    r.fit(X=relief_data_X,y=relief_data_y)\n",
        "    top_features = r.top_features_\n",
        "    feature_importances = r.feature_importances_\n",
        "    stop_fit = time.time()\n",
        "\n",
        "    if verbose_:\n",
        "        print(\"Done. Now storing in cache...\")\n",
        "\n",
        "    savedata = ReliefCacheElem(\n",
        "        dataset_X_sha256 = dataset_X_sha256_hash,\n",
        "        dataset_y_sha256 = dataset_y_sha256_hash,\n",
        "        n_neighbors = n_neighbors,\n",
        "        relieff_top_features = top_features,\n",
        "        relieff_feature_importances = feature_importances,\n",
        "        time_of_computation = stop_fit - start_fit)\n",
        "    relief_cache.add(savedata)\n",
        "    with open(relief_cache_filepath, 'wb') as rcf:\n",
        "        pickle.dump(relief_cache, rcf)\n",
        "\n",
        "    if verbose_:\n",
        "        print(\"Done.\")\n",
        "\n",
        "\n",
        "    return top_features[:n_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oas8vnnMQ0uP",
        "outputId": "a07c37ac-a7fa-435f-b6d5-70084bf872a7"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './data/relief_cache.pickle'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(RELIEF_CACHE_FILEPATH,\u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m rcf:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     relief_cache \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(rcf)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(relief_cache),\u001b[39m'\u001b[39m\u001b[39mcached relief runs:\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/relief_cache.pickle'"
          ]
        }
      ],
      "source": [
        "with open(RELIEF_CACHE_FILEPATH,'rb') as rcf:\n",
        "    relief_cache = pickle.load(rcf)\n",
        "    \n",
        "    print(len(relief_cache),'cached relief runs:')\n",
        "\n",
        "    if len(relief_cache) != 0:\n",
        "        samedataset = [e for e in relief_cache if e.dataset_X_sha256 == dataset_X_sha256_hash and e.dataset_y_sha256 == dataset_y_sha256_hash]\n",
        "        print('('+str(len(samedataset))+'/'+str(len(relief_cache)), 'are from the same dataset)')\n",
        "        if len(samedataset) != len(relief_cache):\n",
        "            raise Exception('Some of the cached results are from a different dataset!!')\n",
        "\n",
        "        for i,e in enumerate(relief_cache):\n",
        "            print(i,':',e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kLX_8-4Zaagm"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "class FeatureSelection(Enum):\n",
        "    MANUAL_VARIABLES = 1\n",
        "    MANUAL_LIST = 2\n",
        "    AUTO_ANOVA = 3      # https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_classif.html\n",
        "    AUTO_RELIEF = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVkiDFjjztbM",
        "outputId": "5b9274df-4aa9-41dc-e6e3-62829211ce79"
      },
      "outputs": [
        {
          "ename": "Exception",
          "evalue": "RELIEF CACHE NOT FOUND at './data/relief_cache.pickle'! Comment exception to create empty cache",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X23sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(AUTO_FEATURE_NUMBER)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m best features:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(selected_features))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X23sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39melif\u001b[39;00m FEATURE_SELECTION \u001b[39m==\u001b[39m FeatureSelection\u001b[39m.\u001b[39mAUTO_RELIEF:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X23sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     support \u001b[39m=\u001b[39m relieff_selection(relief_data_X,relief_data_y,AUTO_FEATURE_NUMBER,n_neighbors\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,relief_cache_filepath\u001b[39m=\u001b[39;49mRELIEF_CACHE_FILEPATH,verbose_\u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X23sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     selected_features \u001b[39m=\u001b[39m original_dataset_features\u001b[39m.\u001b[39mcolumns[support]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X23sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(AUTO_FEATURE_NUMBER)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m best features:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(selected_features))\n",
            "\u001b[1;32m/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb Cell 17\u001b[0m in \u001b[0;36mrelieff_selection\u001b[0;34m(X, y, n_features, n_neighbors, relief_cache_filepath, verbose_)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X23sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m##----------------------------------------------##\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X23sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(relief_cache_filepath):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X23sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mRELIEF CACHE NOT FOUND at \u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mrelief_cache_filepath\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m! Comment exception to create empty cache\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X23sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(relief_cache_filepath, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m rcf:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/cimil-01/Develop/timbreClassifier/RELIEF_timbre_classifier.ipynb#X23sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m         pickle\u001b[39m.\u001b[39mdump(\u001b[39mset\u001b[39m(), rcf)\n",
            "\u001b[0;31mException\u001b[0m: RELIEF CACHE NOT FOUND at './data/relief_cache.pickle'! Comment exception to create empty cache"
          ]
        }
      ],
      "source": [
        "%%write_and_run feature_selection.txt\n",
        "\n",
        "# ------------------------------------------------------------------------------------------------------------------------------- #\n",
        "#\n",
        "# FEATURE_SELECTION = FeatureSelection.MANUAL_VARIABLES\n",
        "# FEATURE_SELECTION = FeatureSelection.MANUAL_LIST\n",
        "# FEATURE_SELECTION = FeatureSelection.AUTO_ANOVA\n",
        "FEATURE_SELECTION = FeatureSelection.AUTO_RELIEF\n",
        "AUTO_FEATURE_NUMBER = 80    # If FEATURE_SELECTION is AUTO_ANOVA or AUTO_RELIEF, select this number of features automatically\n",
        "#\n",
        "# ------------------------------------------------------------------------------------------------------------------------------- #\n",
        "\n",
        "if FEATURE_SELECTION == FeatureSelection.MANUAL_VARIABLES:\n",
        "    ''' Features '''\n",
        "    USE_ATTACKTIME_VALUE = True\n",
        "    USE_BARKSPECBRIGHTNESS = True\n",
        "    USE_PEAKSAMPLE_VALUE = True\n",
        "    USE_ZEROCROSSING = False\n",
        "\n",
        "    USE_BARKSPEC = 40 # Number in range [0-50]\n",
        "    USE_BFCC = 40     # Number in range [0-50]\n",
        "    USE_CEPSTRUM = 60 # Number in range [0-353]\n",
        "    USE_MFCC = 30     # Number in range [0-38]\n",
        "\n",
        "    selected_features = get_manual_selected_features(original_dataset_features)\n",
        "elif FEATURE_SELECTION == FeatureSelection.MANUAL_LIST:\n",
        "    selected_features = ['attackTime_value', 'barkSpecBrightness', 'barkSpec_1', 'barkSpec_2', 'barkSpec_3', 'barkSpec_4', 'barkSpec_5', 'barkSpec_6', 'barkSpec_7', 'barkSpec_8', 'barkSpec_9', 'barkSpec_10', 'barkSpec_11', 'barkSpec_12', 'barkSpec_13', 'barkSpec_14', 'barkSpec_15', 'barkSpec_16', 'barkSpec_17', 'barkSpec_18', 'barkSpec_19', 'barkSpec_20', 'barkSpec_21', 'barkSpec_22', 'barkSpec_23', 'barkSpec_24', 'barkSpec_25', 'barkSpec_26', 'barkSpec_27', 'barkSpec_28', 'barkSpec_29', 'barkSpec_30', 'barkSpec_31', 'barkSpec_32', 'barkSpec_33', 'barkSpec_34', 'barkSpec_35', 'barkSpec_36', 'barkSpec_37', 'barkSpec_38', 'barkSpec_39', 'barkSpec_40', 'barkSpec_41', 'barkSpec_42', 'barkSpec_43', 'barkSpec_44', 'barkSpec_45', 'barkSpec_46', 'barkSpec_47', 'barkSpec_48', 'barkSpec_49', 'barkSpec_50', 'bfcc_2', 'bfcc_3', 'bfcc_4', 'bfcc_5', 'bfcc_6', 'bfcc_7', 'bfcc_8', 'bfcc_9', 'bfcc_10', 'bfcc_11', 'bfcc_12', 'bfcc_13', 'bfcc_15', 'bfcc_16', 'bfcc_17', 'bfcc_18', 'bfcc_19', 'bfcc_20', 'bfcc_21', 'bfcc_25', 'bfcc_26', 'bfcc_27', 'bfcc_28', 'bfcc_29', 'bfcc_30', 'bfcc_31', 'bfcc_35', 'bfcc_36', 'bfcc_37', 'bfcc_39', 'bfcc_40', 'bfcc_42', 'bfcc_43', 'bfcc_44', 'bfcc_45', 'bfcc_46', 'bfcc_48', 'cepstrum_1', 'cepstrum_2', 'cepstrum_3', 'cepstrum_4', 'cepstrum_5', 'cepstrum_6', 'cepstrum_7', 'cepstrum_8', 'cepstrum_9', 'cepstrum_10', 'cepstrum_11', 'cepstrum_12', 'cepstrum_13', 'cepstrum_14', 'cepstrum_15', 'cepstrum_16', 'cepstrum_17', 'cepstrum_18', 'cepstrum_19', 'cepstrum_20', 'cepstrum_21', 'cepstrum_22', 'cepstrum_23', 'cepstrum_24', 'cepstrum_25', 'cepstrum_26', 'cepstrum_27', 'cepstrum_28', 'cepstrum_29', 'cepstrum_30', 'cepstrum_31', 'cepstrum_32', 'cepstrum_33', 'cepstrum_34', 'cepstrum_35', 'cepstrum_36', 'cepstrum_37', 'cepstrum_41', 'cepstrum_42', 'cepstrum_43', 'cepstrum_44', 'cepstrum_45', 'cepstrum_46', 'cepstrum_47', 'cepstrum_48', 'cepstrum_49', 'cepstrum_54', 'cepstrum_56', 'cepstrum_59', 'cepstrum_60', 'cepstrum_67', 'cepstrum_72', 'cepstrum_86', 'cepstrum_87', 'cepstrum_108', 'cepstrum_164', 'cepstrum_205', 'cepstrum_206', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'mfcc_14', 'mfcc_15', 'mfcc_16', 'mfcc_17', 'mfcc_18', 'mfcc_19', 'mfcc_20', 'mfcc_21', 'mfcc_22', 'mfcc_23', 'mfcc_24', 'mfcc_25', 'mfcc_26', 'mfcc_32', 'mfcc_33', 'mfcc_34', 'mfcc_35', 'mfcc_36', 'peakSample_value', 'zeroCrossing']\n",
        "elif FEATURE_SELECTION == FeatureSelection.AUTO_ANOVA:\n",
        "    if original_dataset_features.shape[1] != original_feature_number:\n",
        "        raise ValueError(\"ERROR: please import dataset again since you are trying to subset an already processed feature set (\"+str(dataset_features.shape[1])+\"<\"+str(original_feature_number)+\")\")\n",
        "\n",
        "    # ANOVA feature selection for numeric input and categorical output (https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/#:~:text=Feature%20selection%20is%20the%20process,the%20performance%20of%20the%20model)\n",
        "    from sklearn.feature_selection import SelectKBest\n",
        "    from sklearn.feature_selection import f_classif\n",
        "    \n",
        "    fs = SelectKBest(score_func=f_classif, k=AUTO_FEATURE_NUMBER) # Define feature selection\n",
        "    X_selected = fs.fit_transform(original_dataset_features.to_numpy(), dataset_labels.to_numpy().ravel())                         # Apply feature selection\n",
        "    support = fs.get_support(indices=True)                      # Extract selected indexes\n",
        "    selected_features = original_dataset_features.columns[support].tolist()\n",
        "    print(str(AUTO_FEATURE_NUMBER)+\" best features:\" + str(selected_features))\n",
        "elif FEATURE_SELECTION == FeatureSelection.AUTO_RELIEF:\n",
        "    \n",
        "    support = relieff_selection(relief_data_X,relief_data_y,AUTO_FEATURE_NUMBER,n_neighbors=1,relief_cache_filepath=RELIEF_CACHE_FILEPATH,verbose_= True)\n",
        "    selected_features = original_dataset_features.columns[support].tolist()\n",
        "    print(str(AUTO_FEATURE_NUMBER)+\" best features:\" + str(selected_features))\n",
        "    \n",
        "\n",
        "else:\n",
        "    raise Exception(\"ERROR! This type of feature selection is not supported\")\n",
        "\n",
        "dataset_features = original_dataset_features.copy().loc[:,selected_features]\n",
        "print(\"Features reduced \"+('manually' if (FEATURE_SELECTION == FeatureSelection.MANUAL_LIST or FEATURE_SELECTION == FeatureSelection.MANUAL_VARIABLES) else 'automatically')+\" (\"+str(FEATURE_SELECTION)+\") from \"+str(original_feature_number)+\" to : \"+str(dataset_features.shape[1]))\n",
        "\n",
        "\n",
        "\n",
        "with open('feature_selection.txt','a') as fsfile:\n",
        "        fsfile.write('\\n#\\n#\\n#\\n## Selected features: '+str(selected_features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8l58MfkBez_6"
      },
      "outputs": [],
      "source": [
        "# topfeatures = r.top_features_[:AUTO_FEATURE_NUMBER]\n",
        "# # topfeatures.sort()\n",
        "# print(\"top \",AUTO_FEATURE_NUMBER,\" features:\",\"\\n\"+\"\\n\".join([str(idx)+\"\\t\"+str(original_dataset_features.columns[i]) for idx,i in enumerate(topfeatures)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZQMzIdmyLXU"
      },
      "outputs": [],
      "source": [
        "# dataset_features.info(verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjijWNhvkEfX"
      },
      "outputs": [],
      "source": [
        "raise Exception(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxb5oNdswky3"
      },
      "source": [
        "## Evaluate class support\n",
        "(What percentage of dataset entries represent each class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOwPsK_h5r3q"
      },
      "outputs": [],
      "source": [
        "def printSupport (labels_ds):\n",
        "    binc = np.bincount(np.reshape(labels_ds,labels_ds.size))\n",
        "    for i in range(binc.size):\n",
        "        print(\"Class \" + str(i) + \" support: \" + str(\"{:.2f}\".format(binc[i]/sum(binc) * 100)) + \"%\")\n",
        "printSupport(dataset_labels.to_numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w196aHu6YqnH"
      },
      "source": [
        "# Define model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Be14IPJTg_4"
      },
      "outputs": [],
      "source": [
        "%%write_and_run model_architecture_code.txt\n",
        "\n",
        "def define_model_architecture(_verbose = False):\n",
        "    tf.keras.backend.set_floatx('float32')\n",
        "\n",
        "    net_width = 100    # <---------------------------\n",
        "\n",
        "    dropout_rate = 0.15 # <---------------------------\n",
        "\n",
        "    model = tf.keras.models.Sequential([                    # Dense | BatchNorm | Dropout |\n",
        "        tf.keras.layers.Dense(net_width,activation='relu',\n",
        "                              kernel_initializer='he_uniform'), #   X   |           |         |\n",
        "        tf.keras.layers.BatchNormalization(),                   #       |     X     |         |\n",
        "        tf.keras.layers.Dropout(dropout_rate),                  #       |           |    X    |\n",
        "        tf.keras.layers.Dense(net_width,activation='relu',\n",
        "                              kernel_initializer='he_uniform'), #   X   |           |         |\n",
        "        tf.keras.layers.BatchNormalization(),                   #       |     X     |         |\n",
        "        tf.keras.layers.Dropout(dropout_rate),                  #       |           |    X    |\n",
        "        tf.keras.layers.Dense(net_width,activation='relu',\n",
        "                              kernel_initializer='he_uniform'), #   X   |           |         |\n",
        "        tf.keras.layers.BatchNormalization(),                   #       |     X     |         |\n",
        "        tf.keras.layers.Dropout(dropout_rate),                  #       |           |    X    |\n",
        "        tf.keras.layers.Dense(net_width,activation='relu',\n",
        "                              kernel_initializer='he_uniform'), #   X   |           |         |\n",
        "        tf.keras.layers.Dense(8)\n",
        "    ])\n",
        "\n",
        "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    model._name = \"guitar_timbre_classifier_\" + timestr\n",
        "    if _verbose:\n",
        "        print(\"Created model: '\" + model.name + \"'\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR9dPdKEdcIe"
      },
      "source": [
        "\n",
        "### Define optimizer and compile model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kOMPQBTXVXb"
      },
      "outputs": [],
      "source": [
        "def compile_model(model,optimizer,loss_fn,_verbose = False):\n",
        "    opt = None\n",
        "    if optimizer[\"method\"] == \"sgd\":\n",
        "        opt = keras.optimizers.SGD(learning_rate = optimizer[\"learning_rate\"], momentum=optimizer[\"momentum\"])\n",
        "    elif optimizer[\"method\"] == \"adam\":\n",
        "        opt = keras.optimizers.Adam(learning_rate = optimizer[\"learning_rate\"])\n",
        "    else:\n",
        "        raise Exception(\"Optimizer method not supported\")\n",
        "\n",
        "    model.compile(optimizer=opt,\n",
        "                  loss=loss_fn,\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    if _verbose:\n",
        "        print(\"Model compiled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc66NhrugHsG"
      },
      "source": [
        "# Save Models and Info functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Vbu_AA6dhUU"
      },
      "outputs": [],
      "source": [
        "def save_model_info(model,optimizer,final_cross_validation_results,folds,metrics,outpath, fold_zerobased = None):\n",
        "    info_filename = '/info.txt' if fold_zerobased is None else '/info_fold_'+str(fold_zerobased+1)+'.txt'\n",
        "    assert not (final_cross_validation_results and (fold_zerobased is not None))\n",
        "\n",
        "    with open(outpath + info_filename, \"w\") as f:\n",
        "        if fold_zerobased is not None:\n",
        "            f.write(\"FOLD [\"+str(fold_zerobased+1)+\"/\"+str(folds)+\"]\\n\\n\")\n",
        "        f.write(\"Summary:\\n\")\n",
        "        model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "        f.write(\"\\n\\n\")\n",
        "        f.write(\"Optimizer: \" + optimizer[\"method\"])\n",
        "        if optimizer[\"method\"] == \"sgd\":\n",
        "            f.write(\" lr: \" + str(optimizer[\"learning_rate\"]) + \" momentum: \" + str(optimizer[\"momentum\"]))\n",
        "        elif optimizer[\"method\"] == \"adam\":\n",
        "            f.write(\" lr: \" + str(optimizer[\"learning_rate\"]))\n",
        "        else:\n",
        "            assert(False) # If triggered check new optimizer and add case\n",
        "        f.write(\"\\n\\n\")\n",
        "        if final_cross_validation_results:\n",
        "            f.write(\"Trained for \" + str(train_epochs) + \" epochs for each fold (\"+str(folds)+\"-foldCrossValidation)\\n\")\n",
        "            f.write(\"Single results in the folds directories\\n\")\n",
        "            f.write('\\n\\n-------- Average results --------\\n\\n')\n",
        "        else:\n",
        "            f.write(\"Trained for \" + str(train_epochs) + \" epochs\\n\")\n",
        "\n",
        "            if fold_zerobased is not None:\n",
        "                f.write('(K-Fold cross validation run (fold '+str(fold_zerobased+1)+'/' +str(folds)+ '))\\n')\n",
        "            else:\n",
        "                f.write('(Single run, NO k-fold cross validation)\\n')\n",
        "\n",
        "        for metric in metrics.keys():\n",
        "            value = metrics[metric] if fold_zerobased is None else metrics[metric][fold_zerobased]\n",
        "            f.write(str(metric) + \":\\n\" + str(value) + \"\\n\\n\")\n",
        "        f.close()\n",
        "\n",
        "    # Copy Tensorboard Logs\n",
        "    LOGPATH=outpath+\"/tensorboardlogs\"\n",
        "    %cp -r logs \"$LOGPATH\"\n",
        "\n",
        "    # Copy Model Architecture Code\n",
        "    CODEPATH = outpath + \"/model_architecture.py\"\n",
        "    source = THISDIR + \"model_architecture_code.txt\"\n",
        "    %cp \"$source\" \"$CODEPATH\"\n",
        "\n",
        "    # Copy Feature Selection Code\n",
        "    FSCODEPATH = outpath + \"/feature_selection.py\"\n",
        "    source = THISDIR + \"feature_selection.txt\"\n",
        "    %cp \"$source\" \"$FSCODEPATH\"\n",
        "\n",
        "# def save_fold_info(model,optimizer,fold,folds,testentries,foldmetrics,features_used,outpath):\n",
        "#     with open(outpath + \"/fold_info.txt\", \"w\") as f:\n",
        "#         f.write(\"FOLD [\"+str(fold)+\"/\"+str(folds)+\"]\\n\\n\")\n",
        "#         f.write(\"Summary:\\n\")\n",
        "#         model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
        "#         f.write(\"\\n\\n\")\n",
        "#         f.write(\"Optimizer: \" + optimizer[\"method\"])\n",
        "#         if optimizer[\"method\"] == \"sgd\":\n",
        "#             f.write(\" lr: \" + str(optimizer[\"learning_rate\"]) + \" momentum: \" + str(optimizer[\"momentum\"]))\n",
        "#         elif optimizer[\"method\"] == \"adam\":\n",
        "#             f.write(\" lr: \" + str(optimizer[\"learning_rate\"]))\n",
        "#         else:\n",
        "#             assert(False) # If triggered check new optimizer and add case\n",
        "#         f.write(\"\\n\\n\")\n",
        "#         f.write(\"Trained for \" + str(train_epochs))\n",
        "#         f.write(\"\\n\\n\")\n",
        "#         f.write(\"Results on the test fold (\" + str(testentries) + \" entries)\")\n",
        "#         f.write(\"\\n\\n\")\n",
        "#         f.write(str(foldmetrics[\"confusion_matrix\"]) + \"\\n\")\n",
        "#         f.write(str(foldmetrics[\"printable_classification_report\"]) + \"\\n\")\n",
        "#         f.write(\"Classes names\" + str(CLASSES_DESC) + \"\\n\")\n",
        "#         f.write(\"\\n\\n\")\n",
        "#         f.write(\"Features used:\\n\" + str(features_used))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0iA0sVlINRz"
      },
      "source": [
        "# Prepare Logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTVv1XlUOgBh"
      },
      "outputs": [],
      "source": [
        "!rm -rf ./logs # Clear logs if necessary\n",
        "!sleep 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2NMIioKEYyP"
      },
      "outputs": [],
      "source": [
        "def start_tensorboard(tb_dir,logname):\n",
        "    log_dir = tb_dir\n",
        "    if logname is not None: \n",
        "        log_dir += logname\n",
        "    return tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "tb_dir = \"logs/fit/\"\n",
        "%tensorboard --logdir $tb_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY1u63rqX7fn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_history(train_metric, validation_metric, title, xlabel, ylabel, filename=None, show = False):\n",
        "    fig, ax = plt.subplots(figsize=(5, 3))\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.plot(train_metric)\n",
        "    ax.plot(validation_metric)\n",
        "    ax.legend(['Training','Validation'])\n",
        "    if show:\n",
        "        fig.show()\n",
        "    if filename is not None:\n",
        "        plt.savefig(filename+\".pdf\",bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qExZCK5ipvaa"
      },
      "source": [
        "F1-Score on Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hBHvhH2punc"
      },
      "outputs": [],
      "source": [
        "def macroweighted_f1(y_true,y_pred):\n",
        "    f1scores = []\n",
        "    numSamples = []\n",
        "    for selclass in CLASSES:\n",
        "        classSelection = (y_true == (np.ones(np.shape(y_true)[0])*selclass))\n",
        "        numSamples.append(sum(classSelection))\n",
        "        classPrediction = (y_pred == (np.ones(np.shape(y_true)[0])*selclass))\n",
        "        true_positives = np.sum(np.logical_and(classSelection,(y_true == y_pred)))\n",
        "\n",
        "        precision = 1.0 * true_positives / np.sum(classPrediction)\n",
        "        recall = 1.0 * true_positives / np.sum(classSelection)\n",
        "        f1score = 2 /((1/precision)+(1/recall))\n",
        "        f1scores.append(f1score)\n",
        "    macroWeightedF1 = sum(np.array(f1scores) * np.array(numSamples)) / sum(numSamples)\n",
        "    return macroWeightedF1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SQi2z0Hw2Km"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(y_true, y_pred,_verbose = False):\n",
        "    accuracy = np.sum(y_pred == y_true)/np.shape(y_true)[0]\n",
        "    f1mw = macroweighted_f1(y_true,y_pred)\n",
        "    confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    classification_report = metrics.classification_report(y_true, y_pred, digits=6,target_names = CLASSES_DESC.values(),output_dict=True)\n",
        "    printable_classification_report = metrics.classification_report(y_true, y_pred, digits=4,target_names = CLASSES_DESC.values())\n",
        "\n",
        "    if _verbose:\n",
        "        print(\"Test Accuracy: \" + str(accuracy) + \"\\nTest macro_weighted_avg f1-score: \" + str(f1mw)+'\\n'+str(confusion_matrix)+'\\n'+str(printable_classification_report))\n",
        "\n",
        "    return accuracy, f1mw, confusion_matrix, classification_report, printable_classification_report\n",
        "\n",
        "# print(compute_metrics([1,2,3,4,5,6,7,8],[1,2,2,2,5,6,2,7], _verbose = True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEGBYnUF1vXn"
      },
      "source": [
        "# Prepare TFLite conversion and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAvtjWCwxx1I"
      },
      "outputs": [],
      "source": [
        "# TFLite conversion function\n",
        "def convert2tflite(tf_model_dir,tflite_model_dir = None,model_name=\"model\",quantization=None,dataset=None):\n",
        "    assert (quantization==None or quantization==\"dynamic\" or quantization==\"float-fallback\" or quantization==\"full\")\n",
        "    # Convert the model saved in the previous step.\n",
        "    converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_dir)\n",
        "    if quantization is not None:\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        if quantization == \"full\" or quantization==\"float-fallback\":\n",
        "            assert dataset is not None\n",
        "            def representative_dataset():\n",
        "                for data in tf.data.Dataset.from_tensor_slices((dataset)).batch(1).take(100):\n",
        "                    yield [tf.dtypes.cast(data, tf.float32)]\n",
        "            converter.representative_dataset = representative_dataset\n",
        "        if quantization == \"full\":\n",
        "            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "            converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "            converter.inference_output_type = tf.int8  # or tf.uint8\n",
        "        if quantization == \"dynamic\":\n",
        "            assert dataset is None\n",
        "\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Save the TF Lite model.\n",
        "    if tflite_model_dir is None:\n",
        "        TF_MODEL_PATH = tf_model_dir + \"/\" + model_name + '.tflite'\n",
        "    else:\n",
        "        TF_MODEL_PATH = tflite_model_dir + \"/\" + model_name + '.tflite'\n",
        "\n",
        "    with tf.io.gfile.GFile(TF_MODEL_PATH, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "## USAGE\n",
        "# model_path = MODELFOLDER + \"/\" + RUN_NAME + \"/fold_1\"\n",
        "# convert2tflite(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6wGuSE91syp"
      },
      "outputs": [],
      "source": [
        "def test_tflite_model(model_path,X_test,y_test,first_layer_is_conv,verbose_test = False):\n",
        "    tflite_interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "    input_details = tflite_interpreter.get_input_details()[0]\n",
        "    output_details = tflite_interpreter.get_output_details()[0]\n",
        "    \n",
        "    if verbose_test:\n",
        "        print(\"+--------------------------------------------+\\n| Testing the TF lite model saved            |\\n+--------------------------------------------+\\n\")\n",
        "        print(\"[Model loaded]\\n\")\n",
        "        print(\"\\n== Input details ==\\nname:\"+ str(input_details['name']) + \"\\nshape:\"+str(input_details['shape']) +  \"\\ntype:\"+str(input_details['dtype']))\n",
        "        print(\"\\n== Output details ==\\nname:\"+str(output_details['name']) + \"\\nshape:\"+str(output_details['shape']) + \"\\ntype:\"+str(output_details['dtype']))\n",
        "        print(\"+--------------------------------------------+\\n| Testing on TEST set...                     |\\n+--------------------------------------------+\\n\")\n",
        "    \n",
        "    tflite_interpreter.allocate_tensors()\n",
        "    y_pred = list()\n",
        "    for i in range(X_test.shape[0]):\n",
        "        extracted_test_sample = np.array(X_test[i:i+1]).astype(np.float32)\n",
        "        \n",
        "        # Quantize inputs if necessary (full uint model)\n",
        "        if input_details['dtype'] is np.int8:\n",
        "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "            extracted_test_sample = (extracted_test_sample / input_scale + input_zero_point).astype(np.int8)\n",
        "\n",
        "        if first_layer_is_conv:\n",
        "            input_tensor = np.expand_dims(extracted_test_sample,axis=2).astype(input_details[\"dtype\"])\n",
        "        else:\n",
        "            input_tensor = extracted_test_sample\n",
        "\n",
        "        if verbose_test:\n",
        "            print(\"Setting \"+str(input_tensor.shape)+\" \"+str(input_tensor.dtype)+\" as input\")\n",
        "\n",
        "        tflite_interpreter.set_tensor(input_details['index'], input_tensor)\n",
        "        tflite_interpreter.invoke()\n",
        "        prediction_vec = tflite_interpreter.get_tensor(output_details['index'])\n",
        "\n",
        "        if verbose_test:\n",
        "            print(\"Getting \"+str(prediction_vec.shape)+\" \"+str(prediction_vec.dtype)+\" as output\")\n",
        "\n",
        "        if output_details['dtype'] is np.int8:\n",
        "            output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "            prediction_vec = (prediction_vec + output_zero_point) * output_scale\n",
        "\n",
        "        if verbose_test:\n",
        "            print(prediction_vec)\n",
        "        y_pred.append(np.argmax(prediction_vec))\n",
        "    return y_pred\n",
        "\n",
        "def test_regulartf_model(model_path,X_test,y_test,first_layer_is_conv,verbose_test = False):\n",
        "    imported = tf.keras.models.load_model(model_path)\n",
        "    if first_layer_is_conv:\n",
        "        test_set = np.expand_dims(X_test,axis=2)\n",
        "    else:\n",
        "        test_set = X_test\n",
        "    _, accuracy = imported.evaluate(test_set,  y_test, verbose=2)\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkPVrRtLoxvu"
      },
      "source": [
        "# k-Fold Cross Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISgdGWqRFkMt"
      },
      "outputs": [],
      "source": [
        "# --> Epochs / Batches\n",
        "train_epochs = 3000\n",
        "train_batch = None\n",
        "\n",
        "# --> Cross Validation \n",
        "USE_CROSS_VALIDATION = False\n",
        "# --> Quantize (Dynamic) and test the TF Lite model obtained (quicker but lower accuracy)\n",
        "TEST_QUANTIZATION = True\n",
        "# --> Early Stopping\n",
        "use_early_stopping = False\n",
        "\n",
        "# --> OVERSAMPLING ##############################################\n",
        "DO_OVERSAMPLING = False                                         #\n",
        "                                                                #\n",
        "unique, counts = np.unique(dataset_labels, return_counts=True)  #\n",
        "smote_mask = dict(zip(unique, counts))                          #\n",
        "                                                                #\n",
        "smote_mask[4] = int(smote_mask[5] * 2.5)                        #\n",
        "#################################################################\n",
        "\n",
        "# --> KFOLD RUN #################################################\n",
        "K_SPLITS = 5                                                    #\n",
        "val_split_size = 0.1                                            # percentage of total entries going into the validation set\n",
        "random_state = global_random_state                              # seed for pseudo random generator\n",
        "#################################################################\n",
        "\n",
        "# --> SINGLE RUN ################################################\n",
        "SAVE_MODEL_INFO = True                                          #\n",
        "test_split_size = 0.2                                           #\n",
        "#################################################################\n",
        "\n",
        "DO_TEST = False\n",
        "\n",
        "# optimizer = { \"method\" : \"sgd\", \"learning_rate\" : 0.001, \"momentum\" : 0.7 }\n",
        "optimizer = { \"method\" : \"adam\", \"learning_rate\" : 0.0001 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy9WiiwEpHXf",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "prefix = \"CrossValidated\" if USE_CROSS_VALIDATION else \"Single\"\n",
        "RUN_NAME = prefix + \"Run_\"+time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "cv = StratifiedKFold(n_splits=K_SPLITS,shuffle=True,random_state=random_state)\n",
        "\n",
        "def main_routine(X,y,train_idx=None,test_idx=None,foldcount=None,is_k_fold=False, eval_metrics=None, quantized_eval_metrics=None):\n",
        "    if eval_metrics is None:\n",
        "        raise ValueError(\"provide a eval_metrics dict\")\n",
        "\n",
        "    current_dir = MODELFOLDER + \"/\" + RUN_NAME\n",
        "    %mkdir -p \"$current_dir\"\n",
        "    if is_k_fold:\n",
        "        fold_dir = current_dir + '/Fold_' + str(foldcount)\n",
        "        %mkdir -p \"$fold_dir\"\n",
        "\n",
        "    ### PRINT INFO\n",
        "    if is_k_fold:\n",
        "        print(\"\\nFold [\"+str(foldcount)+\"/\"+str(K_SPLITS)+\"]\")\n",
        "        #### SPLIT DATA\n",
        "        print(\"Selecting Split Data...\")\n",
        "        X_train, y_train = X[train_idx], y[train_idx]\n",
        "        X_test, y_test = X[test_idx], y[test_idx]\n",
        "        # printSupport(y_train)                                                       # Verify that the split is STRATIFIED\n",
        "    else:\n",
        "        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_split_size,random_state=random_state, shuffle=True, stratify = y)\n",
        "        # printSupport(y_train)                                                       # Verify that the split is STRATIFIED\n",
        "        \n",
        "    X_train,X_valid,y_train,y_valid = train_test_split(X_train,y_train,test_size=val_split_size,random_state=random_state, shuffle=True, stratify = y_train)\n",
        "    # printSupport(y_train)                                                       # Verify that the split is STRATIFIED\n",
        "\n",
        "    ### OVERSAMPLE\n",
        "    if DO_OVERSAMPLING:\n",
        "        print(\"Oversampling...\")\n",
        "        VERBOSE_OVERSAMPLING = True\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter(\"ignore\")\n",
        "            if VERBOSE_OVERSAMPLING:\n",
        "                prev_len = y_train.shape[0]\n",
        "            X_train, y_train = SMOTE(smote_mask).fit_sample(X_train, y_train)\n",
        "            if VERBOSE_OVERSAMPLING:\n",
        "                print(\"Increased training samples from \" + str(prev_len) + \" to \" + str(y_train.shape[0]))\n",
        "                printSupport(y_train)\n",
        "\n",
        "    ### DEFINE MODEL\n",
        "    model = define_model_architecture(_verbose = True)\n",
        "    \n",
        "    ### DEFINE LOSS\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    ### PREPARE DATA IN CASE OF A FIRST CONV LAYER IN THE NET\n",
        "    if type(model.layers[0]) == tf.keras.layers.Conv1D:\n",
        "        X_train = np.expand_dims(X_train,axis = 2) # Adapt data for Conv1d ([batch_shape, steps, input_dim] -> in our case indim = 1, steps = features, batchshape = train datset size)\n",
        "        X_valid= np.expand_dims(X_valid,axis = 2)  # Adapt data for Conv1d\n",
        "        X_test= np.expand_dims(X_test,axis = 2)    # Adapt data for Conv1d\n",
        "\n",
        "    ### PERFORM TEST (**OPTIONAL)\n",
        "    if DO_TEST:\n",
        "        predictions = model(X_test[:1].astype('float32')).numpy()\n",
        "        print(\"Predictions: \" + str(predictions) + \"\\nWith Softmax: \" + str(tf.nn.softmax(predictions).numpy()) + \"\\nLoss: \" + str(loss_fn(y_test[:1], predictions).numpy()))\n",
        "\n",
        "    ### COMPILE MODEL\n",
        "    compile_model(model,optimizer,loss_fn,_verbose = True)\n",
        "\n",
        "    ### SETUP TENSORBOARD\n",
        "    tensorboard_callback = start_tensorboard(tb_dir,\"Fold_\"+str(foldcount) if is_k_fold else None)\n",
        "    callbacks=[tensorboard_callback,]\n",
        "    \n",
        "    ### SETUP EARLY STOPPING (only if not in K-fold mode)\n",
        "    if is_k_fold is False and use_early_stopping:\n",
        "        callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200))\n",
        "\n",
        "    # * FIT MODEL *\n",
        "    history = model.fit(X_train, y_train, epochs=train_epochs, validation_data = (X_valid,y_valid),\n",
        "                        callbacks=callbacks,\n",
        "                        batch_size=train_batch)\n",
        "    # Plot history\n",
        "    plot_folder = fold_dir if is_k_fold else current_dir\n",
        "    getval = lambda metric: history.history[metric]\n",
        "    plot_history(getval('accuracy'),getval('val_accuracy'), \"Training and validation accuracy\",\"Epochs\",\"Accuracy\", filename = plot_folder + \"/AccuracyPlot\")\n",
        "    plot_history(getval('loss'),    getval('val_loss'),     \"Training and validation loss\",\"Epochs\",\"Accuracy\",     filename = plot_folder + \"/LossPlot\")\n",
        "    plt.close()\n",
        "    plt.ioff()\n",
        "\n",
        "    # * TEST MODEL *\n",
        "    # keras_test_loss, keras_test_accuracy = model.evaluate(X_test,  y_test, verbose=2) # Keras solution, might not be needed\n",
        "    y_true = np.squeeze(y_test)\n",
        "    y_pred = np.argmax(model(X_test),axis=1)\n",
        "    cm_acc, f1mw, cm_conf_matrix, cm_classf_report, cm_printable_classf_report = compute_metrics(y_true, \\\n",
        "                                                                                                 y_pred, \\\n",
        "                                                                                                 _verbose=True)\n",
        "    eval_metrics[\"accuracy\"].append(cm_acc)\n",
        "    eval_metrics[\"f1_weightedmacroavg\"].append(f1mw)\n",
        "    eval_metrics[\"confusion_matrix\"].append(cm_conf_matrix)\n",
        "    eval_metrics[\"classification_report\"].append(cm_classf_report)\n",
        "    eval_metrics[\"printable_classification_report\"].append(cm_printable_classf_report)\n",
        "\n",
        "    SAVED_MODEL_PATH = None\n",
        "    if is_k_fold:\n",
        "        # Save fold history\n",
        "        with open(fold_dir+\"/history_fold_\"+str(foldcount)+\".pickle\",'wb') as picklefile:\n",
        "            pickle.dump(history.history,picklefile)\n",
        "\n",
        "        # Save the entire model as a SavedModel.\n",
        "        model.save(fold_dir)\n",
        "        SAVED_MODEL_PATH = fold_dir\n",
        "    else:\n",
        "        assert len(eval_metrics['accuracy']) == 1\n",
        "        \n",
        "        # Save the entire model as a SavedModel.\n",
        "        model.save(current_dir)\n",
        "        with open(current_dir+\"/history.pickle\",'wb') as picklefile:\n",
        "            pickle.dump(history.history,picklefile)\n",
        "        SAVED_MODEL_PATH = current_dir\n",
        "\n",
        "    if TEST_QUANTIZATION:\n",
        "        assert quantized_eval_metrics is not None\n",
        "        model_filename = 'partially_quantized_test_model'\n",
        "        # Convert and save lite model\n",
        "        convert2tflite(SAVED_MODEL_PATH,model_name=model_filename,quantization=\"dynamic\")\n",
        "        # Load and Test lite model\n",
        "        y_quant_pred = test_tflite_model(SAVED_MODEL_PATH+'/'+model_filename+'.tflite',X_test,y_test,type(model.layers[0]) == tf.keras.layers.Conv1D,verbose_test = False)\n",
        "        # Compute Test Metrics\n",
        "        cm_acc, f1mw, cm_conf_matrix, cm_classf_report, cm_printable_classf_report = compute_metrics(y_true, \\\n",
        "                                                                                                     y_quant_pred, \\\n",
        "                                                                                                     _verbose=True)\n",
        "        quantized_eval_metrics[\"accuracy\"].append(cm_acc)\n",
        "        quantized_eval_metrics[\"f1_weightedmacroavg\"].append(f1mw)\n",
        "        quantized_eval_metrics[\"confusion_matrix\"].append(cm_conf_matrix)\n",
        "        quantized_eval_metrics[\"classification_report\"].append(cm_classf_report)\n",
        "        quantized_eval_metrics[\"printable_classification_report\"].append(cm_printable_classf_report)\n",
        "\n",
        "    # Now that all the tests are performed, all the info can be saved\n",
        "\n",
        "    if is_k_fold:\n",
        "        metrics_to_save = {}\n",
        "        metrics_to_save.update({'def_model_'+key:value for (key,value) in eval_metrics.items()})\n",
        "        if TEST_QUANTIZATION:\n",
        "            metrics_to_save.update({'quant_model_'+key:value for (key,value) in quantized_eval_metrics.items()})\n",
        "\n",
        "        # save_fold_info(model,optimizer,foldcount,K_SPLITS,X_test.shape[0],eval_metrics,list(dataset_features.columns),fold_dir)\n",
        "        save_model_info(model,\n",
        "                        optimizer,\n",
        "                        False,K_SPLITS,\n",
        "                        metrics_to_save,\n",
        "                        fold_dir,\n",
        "                        fold_zerobased=foldcount-1)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orQZbq4df5jK"
      },
      "outputs": [],
      "source": [
        "'''Call the main routine for each fold'''\n",
        "result_model = []\n",
        "\n",
        "with tf.device('/cpu:0'):\n",
        "\n",
        "    evaluation_metrics = { \"accuracy\" : [], \"f1_weightedmacroavg\" : [], \"confusion_matrix\" : [],\"classification_report\" : [],\"printable_classification_report\" : [] }\n",
        "    quantized_model_evaluation_metrics = { \"accuracy\" : [], \"f1_weightedmacroavg\" : [], \"confusion_matrix\" : [],\"classification_report\" : [],\"printable_classification_report\" : [] }\n",
        "\n",
        "    X = dataset_features.to_numpy()\n",
        "    y = dataset_labels.to_numpy()\n",
        "\n",
        "    if USE_CROSS_VALIDATION:\n",
        "        foldcount = 1\n",
        "        for train_idx, test_idx in cv.split(X, y):\n",
        "            result_model.append(main_routine(dataset_features.to_numpy(), \\\n",
        "                                dataset_labels.to_numpy(), \\\n",
        "                                train_idx, test_idx, \\\n",
        "                                foldcount,  \\\n",
        "                                USE_CROSS_VALIDATION, \\\n",
        "                                evaluation_metrics,  \\\n",
        "                                quantized_eval_metrics = quantized_model_evaluation_metrics))\n",
        "            foldcount += 1\n",
        "    else:\n",
        "        result_model = main_routine(X, \\\n",
        "                                    y, \\\n",
        "                                    eval_metrics = evaluation_metrics, \\\n",
        "                                    quantized_eval_metrics = quantized_model_evaluation_metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLTufCRmlpIW"
      },
      "source": [
        "# Cross Validation average results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOqw9k1wlWZC"
      },
      "source": [
        "## Utilities for reports and metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvpD2bFcYcCi"
      },
      "outputs": [],
      "source": [
        "def report_average(reports):\n",
        "    mean_dict = dict()\n",
        "    for label in reports[0].keys():\n",
        "        dictionary = dict()\n",
        "\n",
        "        if label in 'accuracy':\n",
        "            mean_dict[label] = sum(d[label] for d in reports) / len(reports)\n",
        "            continue\n",
        "\n",
        "        for key in reports[0][label].keys():\n",
        "            dictionary[key] = sum(d[label][key] for d in reports) / len(reports)\n",
        "        mean_dict[label] = dictionary\n",
        "\n",
        "    return mean_dict\n",
        "\n",
        "def classification_report_dict2print(report):\n",
        "    ret = \"\"\n",
        "    classes = list(report.keys())[0:-3]\n",
        "    summary_metrics = list(report.keys())[-3:]\n",
        "    longest_1st_column_name = max([len(key) for key in report.keys()])\n",
        "    ret = ' ' * longest_1st_column_name\n",
        "    ret += '  precision    recall  f1-score   support\\n\\n'\n",
        "\n",
        "    METRIC_DECIMAL_DIGITS = 4\n",
        "    metric_digits = METRIC_DECIMAL_DIGITS + 2 # add 0 and dot\n",
        "\n",
        "    header_spacing = 1\n",
        "    metrics = list(report[classes[0]].keys())\n",
        "    longest_1st_row_name = max([len(key) for key in report[classes[0]].keys()]) + header_spacing\n",
        "\n",
        "    for classname in classes:\n",
        "        ret += (' '*(longest_1st_column_name-len(classname))) + classname + ' '\n",
        "        for metric in metrics:\n",
        "            if metric != \"support\":\n",
        "                ret += (' '*(longest_1st_row_name-metric_digits))\n",
        "                ret += \"%.4f\" % round(report[classname][metric],METRIC_DECIMAL_DIGITS)\n",
        "            else:\n",
        "                current_support_digits = len(str(int(report[classname][metric])))\n",
        "                ret += (' '*(longest_1st_row_name-current_support_digits))\n",
        "                ret += \"%d\" % round(report[classname][metric],0)\n",
        "        ret += '\\n'\n",
        "    ret += '\\n'\n",
        "\n",
        "    # Accuracy\n",
        "    ret += (' '*(longest_1st_column_name-len(summary_metrics[0]))) + summary_metrics[0] + ' '\n",
        "    ret += 2* (' '*longest_1st_row_name)\n",
        "    ret += (' '*(longest_1st_row_name-metric_digits))\n",
        "    ret += \"%.4f\" % round(report[\"accuracy\"],METRIC_DECIMAL_DIGITS)\n",
        "    current_support_digits = len(str(int(report[summary_metrics[-1]]['support'])))\n",
        "    ret += (' '*(longest_1st_row_name-current_support_digits))\n",
        "    ret += \"%d\" % round(report[summary_metrics[-1]]['support'],0)\n",
        "    ret += '\\n'\n",
        "  \n",
        "  \n",
        "    for classname in summary_metrics[1:]:\n",
        "        ret += (' '*(longest_1st_column_name-len(classname))) + classname + ' '\n",
        "        for metric in metrics:\n",
        "            if metric != \"support\":\n",
        "                ret += (' '*(longest_1st_row_name-metric_digits))\n",
        "                ret += \"%.4f\" % round(report[classname][metric],METRIC_DECIMAL_DIGITS)\n",
        "            else:\n",
        "                current_support_digits = len(str(int(report[classname][metric])))\n",
        "                ret += (' '*(longest_1st_row_name-current_support_digits))\n",
        "                ret += \"%d\" % round(report[classname][metric],0)\n",
        "        ret += '\\n'\n",
        "    ret += '\\n'\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vw1nmcpmApM"
      },
      "source": [
        "## Compute average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-xQAAnQu6BO"
      },
      "outputs": [],
      "source": [
        "if USE_CROSS_VALIDATION:\n",
        "    assert len(evaluation_metrics['accuracy']) == K_SPLITS\n",
        "    \n",
        "    printable_avg_report = classification_report_dict2print(report_average(evaluation_metrics[\"classification_report\"]))\n",
        "    qm_printable_avg_report = classification_report_dict2print(report_average(quantized_model_evaluation_metrics[\"classification_report\"]))\n",
        "    metrics_to_save = {\"avg_classification_report\" : printable_avg_report, \"avg_classification_report_for_quantized_model\" : qm_printable_avg_report}\n",
        "else:\n",
        "    assert len(evaluation_metrics['accuracy']) == 1\n",
        "    metrics_to_save = {}\n",
        "    for metric in evaluation_metrics.keys():\n",
        "        metrics_to_save[metric] = evaluation_metrics[metric][0]\n",
        "    for metric in quantized_model_evaluation_metrics.keys():\n",
        "        metrics_to_save['quantizedmod_'+str(metric)] = quantized_model_evaluation_metrics[metric][0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sYtK9DZu64h"
      },
      "source": [
        "# Save Model Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNDoHM4gXw5x"
      },
      "outputs": [],
      "source": [
        "if SAVE_MODEL_INFO:\n",
        "    current_dir = MODELFOLDER + \"/\" + RUN_NAME\n",
        "    %mkdir -p \"$current_dir\"\n",
        "\n",
        "    save_model_info(result_model[0] if type(result_model) == list else result_model,\n",
        "                    optimizer,\n",
        "                    USE_CROSS_VALIDATION,K_SPLITS,\n",
        "                    metrics_to_save,\n",
        "                    current_dir)\n",
        "else:\n",
        "    print(\"RESULTS\\n\\n\" + metrics_to_save)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl7ZdTjKVcE3"
      },
      "source": [
        "# Train final model on the entire dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT6_bSsfVbiH"
      },
      "outputs": [],
      "source": [
        "use_early_stopping = False\n",
        "\n",
        "### DEFINE MODEL\n",
        "final_model,loss_fn = define_model_architecture(_verbose = True)\n",
        "\n",
        "### PREPARE DATA IN CASE OF A FIRST CONV LAYER IN THE NET\n",
        "if type(final_model.layers[0]) == tf.keras.layers.Conv1D:\n",
        "    X_all = np.expand_dims(X,axis = 2) # Adapt data for Conv1d ([batch_shape, steps, input_dim] -> in our case indim = 1, steps = features, batchshape = train datset size)\n",
        "else:\n",
        "    X_all = X\n",
        "\n",
        "\n",
        "### COMPILE MODEL\n",
        "compile_model(final_model,optimizer,loss_fn,_verbose = True)\n",
        "\n",
        "### SETUP TENSORBOARD\n",
        "tensorboard_callback = start_tensorboard(tb_dir,None)\n",
        "callbacks=[tensorboard_callback,]\n",
        "\n",
        "### SETUP EARLY STOPPING (only if not in K-fold mode)\n",
        "if use_early_stopping:\n",
        "    callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='min', verbose=1, patience=200))\n",
        "\n",
        "# * FIT MODEL *\n",
        "final_model.fit(X_all, y, epochs=train_epochs,\n",
        "                callbacks=callbacks,\n",
        "                batch_size=train_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXJ9wBMbb4sp"
      },
      "outputs": [],
      "source": [
        "final_model_dir = MODELFOLDER + \"/\" + RUN_NAME + \"/finalModel\"\n",
        "%mkdir -p \"$final_model_dir\"\n",
        "\n",
        "final_model.save(final_model_dir)\n",
        "\n",
        "# Convert and save lite model (Non quantized)\n",
        "convert2tflite(final_model_dir,model_name='final_model',quantization=None)\n",
        "# Convert and save lite model (Dynamically quantized)\n",
        "convert2tflite(final_model_dir,model_name='final_model_dynquant',quantization=\"dynamic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pBrSDphxyxL"
      },
      "source": [
        "# Save the model for TF Lite\n",
        "## *(Only if not a Cross Validated run)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3ScdRpC-m_J"
      },
      "outputs": [],
      "source": [
        "# if USE_CROSS_VALIDATION is False:\n",
        "#     model_path = MODELFOLDER + \"/\" + RUN_NAME\n",
        "#     convert2tflite(model_path)                                                # standard TFLITE model\n",
        "#     convert2tflite(model_path,model_name=\"model_partially_quantized\",quantization=\"dynamic\")   # Partial quantization  https://www.tensorflow.org/lite/performance/post_training_quantization#dynamic_range_quantization\n",
        "    \n",
        "#     quantization_dataset = X\n",
        "#     if type(result_model.layers[0]) == tf.keras.layers.Conv1D:\n",
        "#         quantization_dataset = np.expand_dims(X,axis = 2) # Adapt data for Conv1d\n",
        "    \n",
        "#     convert2tflite(model_path,model_name=\"model_float_fallback\",quantization=\"float-fallback\",dataset=quantization_dataset) # https://www.tensorflow.org/lite/performance/post_training_integer_quant#convert_using_float_fallback_quantization\n",
        "#     convert2tflite(model_path,model_name=\"model_fully_quantized\",quantization=\"full\",dataset=quantization_dataset)          # FULL uint8 quantization https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnPqZ8k4box0"
      },
      "outputs": [],
      "source": [
        "# first_layer_is_conv = (type(result_model.layers[0]) == tf.keras.layers.Conv1D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QdCLmkgzonI"
      },
      "outputs": [],
      "source": [
        "# TEST_SAVED_MODEL = None\n",
        "# # TEST_SAVED_MODEL = 'model.tflite'\n",
        "# # TEST_SAVED_MODEL = 'model_partially_quantized.tflite'\n",
        "# # TEST_SAVED_MODEL = 'model_float_fallback.tflite'\n",
        "# # TEST_SAVED_MODEL = 'model_fully_quantized.tflite'\n",
        "# # TEST_SAVED_MODEL = 'quant_aware_model.tflite'\n",
        "# # TEST_SAVED_MODEL = 'saved_model.pb'\n",
        "# verbose_test = False\n",
        "\n",
        "# def test_generic_model(model_filename,model_path,X_test,Y_test,first_layer_is_conv,verbose_test = False):\n",
        "#     if model_filename.split('.')[-1] == 'tflite':\n",
        "#         y_pred = test_tflite_model(model_path+'/'+model_filename,X_test,y_test,first_layer_is_conv,verbose_test = verbose_test)\n",
        "#         correct = np.count_nonzero((np.array(y_pred) == np.ravel(y_test)).astype(int))\n",
        "#         total = np.shape(y_test)[0]\n",
        "#         accuracy = round(correct/total,4)\n",
        "#     elif model_filename.split('.')[-1] == 'pb':\n",
        "#         accuracy = test_regulartf_model(model_path,X_test,y_test,first_layer_is_conv,verbose_test = verbose_test)\n",
        "#     else:\n",
        "#         raise ValueError(\"\")\n",
        "\n",
        "#     return accuracy\n",
        "\n",
        "# if USE_CROSS_VALIDATION is False and TEST_SAVED_MODEL is not None:\n",
        "#     assert np.max([len(ev_metric) for ev_metric in evaluation_metrics]) == K_SPLITS\n",
        "\n",
        "#     target_accuracy = evaluation_metrics['accuracy'][0]\n",
        "#     accuracy = test_generic_model(TEST_SAVED_MODEL,model_path,X_test,Y_test,first_layer_is_conv)\n",
        "\n",
        "#     epsilon = 1e-4\n",
        "#     EQUAL_ACCURACY = abs(target_accuracy - accuracy) < epsilon\n",
        "\n",
        "#     print(\"accuracy: \" + str(accuracy))\n",
        "\n",
        "#     if EQUAL_ACCURACY:\n",
        "#         print(\"Accuracy of the original model and the saved TF model correspond(on same test set)\")\n",
        "#     else:\n",
        "#         raise ValueError('Accuracy does not match target (Target: '+str(target_accuracy)+' but got '+str(accuracy)+' instead)')\n",
        "# else:\n",
        "#     print(\"TF model testing is disabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERYDqiDVXUqX"
      },
      "source": [
        "# Quantization aware fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2QJCdx9HOfW"
      },
      "outputs": [],
      "source": [
        "#################################################\n",
        "PERFORM_QUANZATION_AWARE_TRAINING = False       #\n",
        "#################################################\n",
        "if PERFORM_QUANZATION_AWARE_TRAINING:\n",
        "    !pip install tensorflow_model_optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5W8KuwyXTsX"
      },
      "outputs": [],
      "source": [
        "if PERFORM_QUANZATION_AWARE_TRAINING:\n",
        "    imported_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    import tensorflow_model_optimization as tfmot\n",
        "\n",
        "    quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "    # q_aware stands for for quantization aware.\n",
        "    q_aware_model = None\n",
        "    q_aware_model = quantize_model(imported_model)\n",
        "\n",
        "    # `quantize_model` requires a recompile.\n",
        "    _,loss_fn = define_model_architecture(_verbose = True)  # Get only the loss function\n",
        "    compile_model(q_aware_model,optimizer,loss_fn,_verbose = True)  # Recompile the quantization aware model\n",
        "\n",
        "    q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pb9pAqTA0h5"
      },
      "outputs": [],
      "source": [
        "if PERFORM_QUANZATION_AWARE_TRAINING:\n",
        "    tb_dir = \"logs2/fit/\"\n",
        "    %tensorboard --logdir $tb_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQPy1nbXtWto"
      },
      "outputs": [],
      "source": [
        "if PERFORM_QUANZATION_AWARE_TRAINING:\n",
        "    finetuning_epochs = 50\n",
        "    tensorboard_callback = start_tensorboard(tb_dir,None)\n",
        "\n",
        "    q_history = q_aware_model.fit(X_train, y_train, epochs=finetuning_epochs, validation_data = (X_valid,y_valid),\n",
        "                                callbacks=[tensorboard_callback],\n",
        "                                batch_size=train_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIbbjlPRx1bx"
      },
      "outputs": [],
      "source": [
        "if PERFORM_QUANZATION_AWARE_TRAINING:\n",
        "    quant_model_path = MODELFOLDER + \"/\" + RUN_NAME + \"/quant_aware_model.tflite\"\n",
        "\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "    quantized_tflite_model = converter.convert()\n",
        "\n",
        "    with tf.io.gfile.GFile(quant_model_path, 'wb') as f:\n",
        "        f.write(quantized_tflite_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
