{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href='https://colab.research.google.com/github/domenicostefani/timbre-classifier/blob/main/expressive-technique-classifier-phase3.ipynb' target='_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAJRnwSBQNbQ"
      },
      "source": [
        "# Phase3 - Model Tester\n",
        "Test with extra recording data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_DIR = 'output/c_acc0.5784_CrossValidatedRun_20221010-162601'\n",
        "import os\n",
        "assert os.path.exists(MODEL_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a2ha_JDqV9I"
      },
      "source": [
        "## Import modules and mount drive folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw8otQ7AQMaV",
        "outputId": "f2355e94-ed49-4038-d33c-b69eb41a1b9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.4.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "import sys\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(\"Tensorflow version: \" + tf.version.VERSION)\n",
        "from packaging import version\n",
        "python_version = re.findall('\\d+\\.\\d+\\.\\d+',sys.version)[0]\n",
        "if version.parse(python_version) <= version.parse(\"3.8.3\"):\n",
        "    print(\"Python version ('\"+python_version+\"') is less than 3.8.3\")\n",
        "    import pickle5 as pickle\n",
        "else: \n",
        "    import pickle\n",
        "import shutil\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import metrics\n",
        "from typing import Tuple\n",
        "\n",
        "global_random_state = 42\n",
        "np.random.seed(global_random_state)\n",
        "tf.random.set_seed(global_random_state)\n",
        "\n",
        "COLAB = 'google.colab' in str(get_ipython())\n",
        "\n",
        "DATAFOLDER = 'data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "\n",
        "for device in physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "\n",
        "print(physical_devices)\n",
        "assert len(tf.config.experimental.list_physical_devices('GPU')) >= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Uhip8r7F4sSv"
      },
      "outputs": [],
      "source": [
        "def drop_unused_features(features_df: pd.DataFrame, inplace = False) -> pd.DataFrame:\n",
        "    if not inplace:\n",
        "        res_df = features_df.copy()\n",
        "    else:\n",
        "        res_df = features_df\n",
        "    if 'attackTime_peaksamp'       not in res_df.columns.to_list() or\\\n",
        "       'attackTime_attackStartIdx' not in res_df.columns.to_list() or\\\n",
        "       'peakSample_index'          not in res_df.columns.to_list():\n",
        "       raise Exception(\"The features dataframe does not contain the required columns!\")\n",
        "\n",
        "    res_df.drop(columns=['attackTime_peaksamp',\\\n",
        "                                'attackTime_attackStartIdx',\\\n",
        "                                'peakSample_index'], inplace=True)\n",
        "    return res_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "-HN56MAc5kjA"
      },
      "outputs": [],
      "source": [
        "# Extract separate DFs\n",
        "# Divide dataset into metadata, features and labels\n",
        "def divide_dataset(features_df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
        "    metadata = features_df.filter(regex='^meta_',axis=1)\n",
        "    labels = features_df.meta_expressive_technique_id\n",
        "    features = features_df.loc[:,[col for col in features_df.columns if col not in metadata.columns]]\n",
        "    # Convert to numeric formats where possible (somehow convert_dtypes doesn't work [https://stackoverflow.com/questions/65915048/pandas-convert-dtypes-not-working-on-numbers-marked-as-objects])\n",
        "    metadata = metadata.apply(pd.to_numeric, errors='ignore')\n",
        "    labels = labels.apply(pd.to_numeric, errors='ignore')\n",
        "    features = features.apply(pd.to_numeric, errors='ignore')\n",
        "    return metadata, features, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjF3Cif5zr1p"
      },
      "source": [
        "## Subset features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read features list from file: \n",
            "['peakSample_value', 'attackTime_value', 'mfcc_7', 'bfcc_7', 'bfcc_3', 'bfcc_4', 'mfcc_3', 'cepstrum_1', 'mfcc_4', 'bfcc_32', 'barkSpec_3', 'cepstrum_5', 'mfcc_5', 'bfcc_5', 'bfcc_6', 'barkSpec_2', 'mfcc_8', 'bfcc_9', 'bfcc_17', 'cepstrum_2', 'barkSpec_7', 'mfcc_10', 'barkSpec_17', 'bfcc_20', 'barkSpec_6', 'barkSpec_8', 'bfcc_30', 'mfcc_34', 'mfcc_6', 'bfcc_10', 'bfcc_34', 'bfcc_8', 'bfcc_18', 'bfcc_22', 'mfcc_9', 'barkSpecBrightness', 'barkSpec_4', 'mfcc_26', 'mfcc_25', 'mfcc_11', 'mfcc_23', 'barkSpec_18', 'barkSpec_5', 'bfcc_16', 'mfcc_27', 'barkSpec_10', 'mfcc_21', 'bfcc_12', 'bfcc_21', 'mfcc_22']\n"
          ]
        }
      ],
      "source": [
        "selected_features = None\n",
        "assert os.path.exists(os.path.join(MODEL_DIR,'info.txt'))\n",
        "with open(os.path.join(MODEL_DIR,'info.txt')) as infofile:\n",
        "    for idx,line in enumerate(infofile.readlines()):\n",
        "        if 'Selected features: ' in line:\n",
        "            s = line\n",
        "            s = re.findall('(?<=Selected features: ).*',s)[0]\n",
        "            s = re.findall('(?<=\\[).*(?=\\])',s)[0].replace('\\'','').replace(' ','').split(',')\n",
        "            selected_features = s\n",
        "assert selected_features is not None\n",
        "\n",
        "print('Read features list from file: \\n'+str(selected_features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "5hBHvhH2punc"
      },
      "outputs": [],
      "source": [
        "def macroweighted_f1(y_true,y_pred):\n",
        "    f1scores = []\n",
        "    numSamples = []\n",
        "    for selclass in CLASSES:\n",
        "        classSelection = (y_true == (np.ones(np.shape(y_true)[0])*selclass))\n",
        "        numSamples.append(sum(classSelection))\n",
        "        classPrediction = (y_pred == (np.ones(np.shape(y_true)[0])*selclass))\n",
        "        true_positives = np.sum(np.logical_and(classSelection,(y_true == y_pred)))\n",
        "\n",
        "        precision = 1.0 * true_positives / np.sum(classPrediction)\n",
        "        recall = 1.0 * true_positives / np.sum(classSelection)\n",
        "        f1score = 2 /((1/precision)+(1/recall))\n",
        "        f1scores.append(f1score)\n",
        "    macroWeightedF1 = sum(np.array(f1scores) * np.array(numSamples)) / sum(numSamples)\n",
        "    return macroWeightedF1\n",
        "\n",
        "def compute_metrics(y_true, y_pred,_verbose = False):\n",
        "    accuracy = np.sum(y_pred == y_true)/np.shape(y_true)[0]\n",
        "    f1mw = macroweighted_f1(y_true,y_pred)\n",
        "    confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
        "    \n",
        "    classification_report = metrics.classification_report(y_true, y_pred, digits=6,target_names = CLASSES_DESC.values(),output_dict=True)\n",
        "    printable_classification_report = metrics.classification_report(y_true, y_pred, digits=4,target_names = CLASSES_DESC.values())\n",
        "\n",
        "    if _verbose:\n",
        "        print(\"Test Accuracy: \" + str(accuracy) + \"\\nTest macro_weighted_avg f1-score: \" + str(f1mw)+'\\n'+str(confusion_matrix)+'\\n'+str(printable_classification_report))\n",
        "\n",
        "    return accuracy, f1mw, confusion_matrix, classification_report, printable_classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"guitar_timbre_classifier_20221010-170918\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_50 (Dense)             (None, 80)                4080      \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dropout_41 (Dropout)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dropout_43 (Dropout)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_44 (Batc (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_45 (Batc (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_46 (Batc (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "batch_normalization_47 (Batc (None, 80)                320       \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 80)                6480      \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 8)                 648       \n",
            "=================================================================\n",
            "Total params: 59,128\n",
            "Trainable params: 57,848\n",
            "Non-trainable params: 1,280\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(MODEL_DIR,'finalModel')\n",
        "assert os.path.exists(model_path)\n",
        "final_model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "print(final_model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing with extra test data\n",
        "This data was extracted from extra recordings, made to test the system in a real life scenario.  \n",
        "Here we test only to veryfy that everything is working here, before making a shift to the real life test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test data from pickle...\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Load the test data \"\"\"\n",
        "\n",
        "TEST_DATA_FILE_PATH = os.path.join(DATAFOLDER,'phase3','20221011_110715_test_onlycorrectdetections.pickle')\n",
        "print(\"Loading test data from pickle...\")\n",
        "with open(TEST_DATA_FILE_PATH,'rb') as pf:\n",
        "    testdataset = pickle.load(pf)\n",
        "testdataset.sort_values(['meta_expressive_technique_id','meta_audiofilePath'],inplace = True)\n",
        "print('Done.')\n",
        "# If this fails, the dataset has changed from the last time the program was run successfully (CHECK THE DATA!!!)\n",
        "assert testdataset.shape == (754,507)\n",
        "# display(testdataset)\n",
        "\n",
        "\n",
        "\"\"\" Drop unused features (like the train/test dataset) \"\"\"\n",
        "\n",
        "drop_unused_features(testdataset,inplace=True)\n",
        "assert testdataset.shape == (754,504)\n",
        "\n",
        "\n",
        "\"\"\" Divide the test data into metadata, features and labels (like the train/test dataset) \"\"\"\n",
        "\n",
        "test_metadata, test_features, test_labels = divide_dataset(testdataset)\n",
        "assert test_metadata.shape[0] == test_features.shape[0] == test_labels.shape[0] == 754\n",
        "assert test_metadata.shape[1] == 9\n",
        "assert test_features.shape[1] == 495\n",
        "\n",
        "\n",
        "\"\"\" Apply the feature selection computed for the train/test set (like the train/test dataset) \"\"\"\n",
        "\n",
        "test_features = test_features.copy().loc[:,selected_features]\n",
        "\n",
        "assert len(selected_features) == final_model.layers[0].get_input_at(0).get_shape().as_list()[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "CLASSES_DESC = {0:\"Kick\",\n",
        "                1:\"Snare 1\",\n",
        "                2:\"Tom\",\n",
        "                3:\"Snare 2\",\n",
        "                4:\"Natural Harmonics\",\n",
        "                5:\"Palm Mute\",\n",
        "                6:\"Pick Near Bridge\",\n",
        "                7:\"Pick Over the Soundhole\"}\n",
        "CLASSES = list(CLASSES_DESC.keys())\n",
        "\n",
        "assert np.equal(np.sort(CLASSES),np.sort(pd.unique(test_labels))).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_49315/1166053901.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  precision = 1.0 * true_positives / np.sum(classPrediction)\n",
            "/tmp/ipykernel_49315/1166053901.py:12: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  f1score = 2 /((1/precision)+(1/recall))\n",
            "/home/cimil-01/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/cimil-01/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/cimil-01/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/cimil-01/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/cimil-01/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/cimil-01/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "DO_WRITE_TO_FILE = True\n",
        "\n",
        "extra_test_x = test_features.to_numpy()\n",
        "extra_test_y = test_labels.to_numpy()\n",
        "\n",
        "\n",
        "y_true = np.squeeze(extra_test_y)\n",
        "y_pred = np.argmax(final_model(extra_test_x),axis=1)\n",
        "cm_acc, f1mw, cm_conf_matrix, cm_classf_report, cm_printable_classf_report = compute_metrics(y_true, \\\n",
        "                                                                                             y_pred, \\\n",
        "                                                                                             _verbose=False)\n",
        "if DO_WRITE_TO_FILE:\n",
        "    infof = open(os.path.join(MODEL_DIR,'info.txt'),'a')\n",
        "    writefunc = infof.write\n",
        "else:\n",
        "    writefunc = print\n",
        "\n",
        "writefunc('______________________________________________________________________________________________________________________________________________________\\n\\n\\n')\n",
        "writefunc('+----------------------------------------------------------------+\\n')\n",
        "writefunc('| Results obtained on extra test recordings with the FINAL MODEL |\\n')\n",
        "writefunc('+----------------------------------------------------------------+\\n\\n')\n",
        "writefunc('Extra-test-Accuracy: '+str(cm_acc)+'\\n\\n')\n",
        "writefunc('Extra-test-F1 Score (weighted average): '+str(f1mw)+'\\n\\n')\n",
        "writefunc('Extra-test-ConfusionMatrix: \\n'+str(cm_conf_matrix)+'\\n\\n')\n",
        "writefunc('Extra-test-Report: \\n'+str(cm_printable_classf_report)+'\\n\\n')\n",
        "\n",
        "\n",
        "if DO_WRITE_TO_FILE:\n",
        "    infof.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "!code $MODEL_DIR/info.txt"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 ('tf-CLONE')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "959cb910f4c92fed33bcbb2d615fe10bd0473a33e22a9b4e00ebf3acf1e03643"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
